{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94628aa",
   "metadata": {},
   "source": [
    "# Mining - Drilling data pipeline solution - Sukari\n",
    "\n",
    "This **solution** will \n",
    "1. Read Mining and Drilling excel files that we currently input them manually daily.\n",
    "2. Do some data cleaning. \n",
    "3. Store cleaned data in a proper way in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90c34fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import time, date\n",
    "import sqlalchemy as sa\n",
    "import warnings\n",
    "\n",
    "# ignore some warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ec528",
   "metadata": {},
   "source": [
    "### 1 - Read Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e82765",
   "metadata": {},
   "source": [
    "#### 1 - A - Mining Data\n",
    "There are 3 excel sheets for Mining:\n",
    "1. Daily Dispatch Master.\n",
    "    - This is our main excel sheet, it has data for **Loads**, **Hours** and **SMU**.\n",
    "    - Loads and Hours are stored as aggregates for every one hour interval, SMU is recorded at shift start and end.\n",
    "2. Daily Production Report.\n",
    "    - Will extract the monthly truck factor from it.\n",
    "3. Daily Production Performance\n",
    "    - Has distances for excavators recorded as aggregates per shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ea9c726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read dispatch master\n",
    "def read_dispatch():\n",
    "    \n",
    "    dispatch_path = 'dispatch/*.xlsx'\n",
    "    dispatch_files = glob.glob(dispatch_path)\n",
    "    dispatch_df = pd.DataFrame()\n",
    "    print('Reading Dispatch Files...\\n')\n",
    "    if len(dispatch_files) < 1 :\n",
    "        raise ValueError('No files to read!')\n",
    "    else : \n",
    "        print('dispatch files number ={}\\n'.format(len(dispatch_files)))\n",
    "        for file in dispatch_files:\n",
    "            print(\"Reading {}\".format(file))\n",
    "            df = pd.read_excel(io=file, sheet_name=\"Fix Database\",  usecols=\"B:W\")\n",
    "            print(\"Columns = {}\".format(len(df.columns)))\n",
    "            dispatch_df = pd.concat([dispatch_df, df], ignore_index=True, axis=0)\n",
    "            print(\"Master df Columns = {}\".format(len(dispatch_df.columns)))\n",
    "            print(\"finished {}\\n\".format(file))\n",
    "            if len(dispatch_df.columns) > 22:\n",
    "                 raise ValueError('Cols are more than 22, check excel sheet format')\n",
    "    print('last dispatch date =', dispatch_df['DATE'].tail(1))\n",
    "    print('\\nDispatch Files Reading Ended Successfully...')\n",
    "    \n",
    "    return dispatch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "edfe4fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read performance master\n",
    "def read_performance():\n",
    "    \n",
    "    performance_path = 'performance/*.xlsx'\n",
    "    performance_files = glob.glob(performance_path)\n",
    "    performance_df = pd.DataFrame()\n",
    "    print('\\nReading Performance Files...\\n')\n",
    "    if len(performance_files) < 1 :\n",
    "        raise ValueError('No files to read!')\n",
    "    else : \n",
    "        print('performance files number =', len(performance_files))\n",
    "        for file in performance_files:\n",
    "            df_ds = pd.read_excel(io=file, sheet_name=\"Distance (dsns)\", skiprows=2, usecols=\"B,C,D\", header=None, names=['DATE','EXC','distance'])\n",
    "            df_ds['shift'] = 'day'\n",
    "            df_ns = pd.read_excel(io=file, sheet_name=\"Distance (dsns)\", skiprows=2, usecols=\"O,P,Q\", header=None, names=['DATE','EXC','distance'])\n",
    "            df_ns['shift'] = 'night'\n",
    "            df = pd.concat([df_ds, df_ns], ignore_index=True, axis=0)\n",
    "            performance_df = pd.concat([performance_df, df], ignore_index=True, axis=0)\n",
    "            print(\"finished {}\".format(file))\n",
    "            print(\"Columns = {}\".format(len(performance_df.columns)))\n",
    "            if len(performance_df.columns) != 4:\n",
    "                 raise ValueError('Cols are not equal to 4, check excel sheet format')\n",
    "    print('last performance date =', performance_df['DATE'].tail(1))\n",
    "    print('\\nPerformance Files Reading Ended Successfully...')\n",
    "    \n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e44329f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read dpr\n",
    "def read_dpr():\n",
    "    \n",
    "    dpr_path = 'dpr/*.xlsx'\n",
    "    dpr_files = glob.glob(dpr_path)\n",
    "    dpr_df = pd.DataFrame()\n",
    "    print('\\nReading dpr Files...\\n')\n",
    "    if len(dpr_files) < 1 :\n",
    "        raise ValueError('No files to read!')\n",
    "    else : \n",
    "        print('dpr files number =', len(dpr_files))\n",
    "        for file in dpr_files:\n",
    "            df = pd.read_excel(file, sheet_name='Data Sheet', usecols=\"A,H,L,M,N\")\n",
    "            dpr_df = pd.concat([dpr_df, df], ignore_index=True, axis=0)\n",
    "            print(\"finished {}\".format(file))\n",
    "            print(\"Columns = {}\".format(len(dpr_df.columns)))\n",
    "            if len(dpr_df.columns) != 5:\n",
    "                 raise ValueError('Cols are not equal to 4, check excel sheet format')\n",
    "    print('last performance date =', dpr_df['Date'].tail(1))\n",
    "    print('\\nPerformance Files Reading Ended Successfully...')\n",
    "    \n",
    "    return dpr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ecb631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reason codes\n",
    "def read_reason_codes():\n",
    "    \n",
    "    reason_codes_path = 'reason_codes/reason_codes.csv'\n",
    "    \n",
    "    print('\\nReading Reason codes...\\n')\n",
    "       \n",
    "    reason_codes = pd.read_csv(reason_codes_path)\n",
    "\n",
    "    print('\\nReason codes Reading Ended Successfully...')\n",
    "    \n",
    "    return reason_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63001b",
   "metadata": {},
   "source": [
    "#### 1 - B - Drilling Data\n",
    "There are 2 excel sheets for Drilling:\n",
    "1. Daily Drilling Data.\n",
    "    - This is our main excel sheet, it has meters drilled aggregated for each hole.\n",
    "2. Rigs Data.\n",
    "    - Has the rigs hours aggregated per shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "05bdc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read daily drilling data\n",
    "def read_drilling():\n",
    "    \n",
    "    daily_data_path = 'drilling/*.xlsx'\n",
    "    daily_data_files = glob.glob(daily_data_path)\n",
    "    meters_df = pd.DataFrame()\n",
    "    rigs_hours_df = pd.DataFrame()\n",
    "    print('\\nReading drilling Files...\\n')\n",
    "    if len(daily_data_files) < 1 :\n",
    "        raise ValueError('No files to read!')\n",
    "    else :\n",
    "        print('daily data files number =', len(daily_data_files))\n",
    "        for file in daily_data_files :         \n",
    "            meters = pd.read_excel(io=file, sheet_name = 'DailyDrillingData', usecols= \"E:V\")\n",
    "            meters_df = pd.concat([meters_df, meters], ignore_index =True, axis=0)\n",
    "            rigs_hours = pd.read_excel(io=file, sheet_name = 'Rigs Data', usecols=\"C:BQ\")\n",
    "            rigs_hours_df = pd.concat([rigs_hours_df, rigs_hours], ignore_index =True, axis=0)\n",
    "    print('last meters date =', meters_df['Date'].tail(1))\n",
    "    print('last rigs_hours date =', rigs_hours_df['Date'].tail(1))\n",
    "    print('\\nDrilling Files Reading Ended Successfully...')\n",
    "    \n",
    "    return meters_df, rigs_hours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc493e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction Process\n",
    "def extract_data():\n",
    "    print('*** START DATA EXTRACTION ***\\n')\n",
    "    \n",
    "    dispatch_df = read_dispatch()\n",
    "    performance_df = read_performance()\n",
    "    dpr_df = read_dpr()\n",
    "    meters_df, rigs_hours_df = read_drilling()\n",
    "    reason_codes_df = read_reason_codes()\n",
    "    \n",
    "    print('\\n***DATA EXTRACTION ENDED ***\\n')\n",
    "    \n",
    "    return dispatch_df, performance_df, dpr_df, meters_df, rigs_hours_df, reason_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78863c4c",
   "metadata": {},
   "source": [
    "### 2 - Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb367f1",
   "metadata": {},
   "source": [
    "#### 2 - A - General data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efa881b",
   "metadata": {},
   "source": [
    "#### 2 - A - Dispatch master cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8d09991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_clean(dfs):\n",
    "    \n",
    "    new_dfs = [df.copy() for df in dfs[:len(dfs)-1]]\n",
    "    # clean column names\n",
    "    for df in new_dfs:\n",
    "        df.columns = df.columns.str.lower().str.replace(' ','_')\n",
    "\n",
    "    # create a new list of dfs\n",
    "    \n",
    "    new_dfs = [df[df['date'].isnull() == False] for df in new_dfs]\n",
    "\n",
    "    return new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b6c021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dispatch\n",
    "def transform_dispatch(df,x):\n",
    "    \n",
    "    print(\"/// dispatch transformation started ///\")\n",
    "\n",
    "    dispatch_df = df[0].copy()\n",
    "\n",
    "    dispatch_df.dropna(how='all', inplace=True)\n",
    "\n",
    "    print('Converting production values to numeric...')\n",
    "    dispatch_df['production_value'] = pd.to_numeric(dispatch_df['production_value'], errors='coerce')\n",
    "    errors = dispatch_df[dispatch_df['production_value'].isna()]\n",
    "    errors_index = errors.index.tolist()\n",
    "    n_errors = len(errors_index)\n",
    "    dispatch_df.drop(index=errors_index, inplace=True)\n",
    "    dispatch_df = dispatch_df[dispatch_df['production_value'] > 0]\n",
    "    print('Found and dropped {} errors'.format(n_errors))\n",
    "\n",
    "    # convert codes to integers\n",
    "    dispatch_df['reason_code'] = dispatch_df['reason_code'].astype('Int64')\n",
    "\n",
    "    # adjust time col\n",
    "    dispatch_df['time'] = dispatch_df['time'].str.split('-').str[0]\n",
    "    dispatch_df['time'] = pd.to_numeric(dispatch_df['time'], errors='coerce')\n",
    "    dispatch_df['time'] = dispatch_df['time'].replace(np.nan, 0).round()\n",
    "\n",
    "    # adjust date col\n",
    "    dispatch_df['date'] = pd.to_datetime(dispatch_df['date'])\n",
    "\n",
    "    # assign dtypes\n",
    "    dispatch_df = dispatch_df.astype({'shift' : 'string', \n",
    "                                'operator_name':'string',\n",
    "                                'crew':'string',\n",
    "                                'reason_activity':'string',\n",
    "                                'engine_state_code':'string',\n",
    "                                'time' : 'Int64',\n",
    "                                'equipment_id':'string',\n",
    "                                'related_equipment':'string',\n",
    "                                'location_pit':'string',\n",
    "                                'material_code':'string',\n",
    "                                'material_type_code':'string', \n",
    "                                'entry_type':'string', \n",
    "                                'destination':'string', \n",
    "                                'reason_code':'Int64',\n",
    "                                'dispatcher_name':'string',\n",
    "                                'activity_code':'Int64'\n",
    "    })\n",
    "\n",
    "    # drop un-needed cols\n",
    "    dispatch_df.drop(columns=['activity','equipment_oem_model', 'cost_code', 'related_equipment_oem_model'], inplace=True)\n",
    "\n",
    "    dispatch_df.sort_values(by=['date','shift','time'], inplace=True)\n",
    "\n",
    "    dispatch_df['time'] = dispatch_df.apply(lambda x : (time(hour=(x['time']) + 12)) \n",
    "        if ((x['shift'] == 'DAY' and x['time'] <8) or (x['shift'] == 'NIGHT' and (x['time'] > 7 and x['time'] <12))) \n",
    "        else (time(hour=0)) if ((x['shift'] == 'NIGHT' and x['time'] ==12)) \n",
    "        else (time(hour=(x['time']))) , axis= 1)\n",
    "\n",
    "    dispatch_df['id_shift'] = dispatch_df['date'].dt.strftime('%d%m%y') + dispatch_df['shift'].str[:1] + dispatch_df['equipment_id'] \n",
    "    dispatch_df = dispatch_df.reindex(columns=['id_shift' ,'date', 'shift', 'time', 'operator_name', 'crew', 'reason_activity',\n",
    "       'engine_state_code', 'equipment_id', 'related_equipment',\n",
    "       'location_pit', 'material_code', 'material_type_code', 'entry_type',\n",
    "       'production_value', 'destination', 'activity_code', 'reason_code',\n",
    "       'dispatcher_name'])\n",
    "\n",
    "    dispatch_df.replace(['0:00:00','00:00:00','0'], np.nan, inplace=True)\n",
    "    dispatch_df['shift'] = dispatch_df['shift'].str.capitalize()\n",
    "\n",
    "    print(\"...Started dispatch splitting...\")\n",
    "\n",
    "    loads_df = dispatch_df[dispatch_df['entry_type'].str.lower() == 'load'].reset_index(drop=True).copy()\n",
    "    hours_df = dispatch_df[dispatch_df['entry_type'].str.lower() == 'hours'].reset_index(drop=True).copy()\n",
    "    smu_df = dispatch_df[dispatch_df['entry_type'].str.lower().str.split().str[0] == 'smu'].reset_index(drop=True).copy()\n",
    "\n",
    "\n",
    "    # clean loads_df\n",
    "    loads_df.drop(columns = ['reason_activity', 'engine_state_code', 'entry_type', 'material_type_code', 'activity_code'], inplace= True)\n",
    "    loads_df.rename(columns={'production_value' : 'loads'}, inplace=True)\n",
    "    loads_df['loads'] = loads_df['loads'].astype('Int64')\n",
    "    #loads_df = loads_df[loads_df['equipment_id'].str[:3] != 'EXC' ]\n",
    "    #loads_df['id_shift'] = loads_df['date'].dt.strftime('%d%m%y') + loads_df['shift'].str[:1] + loads_df['related_equipment']\n",
    "\n",
    "    # add bcm column\n",
    "    loads_df['month_year'] = loads_df['date'].dt.month_name().str[:3] + '-' + loads_df['date'].dt.year.astype('string').str[2:]\n",
    "    loads_df = loads_df.merge(x[['month_year','truck_factor']],on='month_year', how='outer', copy=False)\n",
    "    loads_df['bcm'] = loads_df['loads'] * loads_df['truck_factor']\n",
    "    loads_df.drop(columns=['month_year', 'truck_factor'], inplace=True)\n",
    "    loads_df = loads_df[loads_df['date'].isna() == False]\n",
    "\n",
    "\n",
    "    # clean hours_df\n",
    "    hours_df.drop(columns = ['entry_type', 'related_equipment', 'material_code', 'material_type_code', 'destination'], inplace= True)\n",
    "    hours_df.rename(columns={'production_value' : 'hours'}, inplace=True)\n",
    "    hours_df = hours_df[hours_df['reason_code'].isna() == False]\n",
    "\n",
    "    # clean smu_df\n",
    "    smu_df = smu_df[['date', 'shift', 'equipment_id', 'entry_type', 'production_value', 'dispatcher_name', 'id_shift']]\n",
    "    smu_df = smu_df.pivot_table(index=['id_shift', 'date', 'shift', 'equipment_id', 'dispatcher_name'], columns=['entry_type'])\n",
    "    smu_df.columns = smu_df.columns.droplevel().rename(None)\n",
    "    smu_df = smu_df.reset_index()\n",
    "    smu_df.columns=smu_df.columns.str.lower().str.replace(' ','_')\n",
    "    smu_df = smu_df.reindex(columns=['id_shift', 'date', 'shift', 'equipment_id', 'dispatcher_name', 'smu_start', 'smu_end', 'smu'])\n",
    "    smu_duplicates = smu_df[smu_df.duplicated(['id_shift'])]\n",
    "    smu_df.drop_duplicates(subset = 'id_shift', keep='last', inplace= True, ignore_index=True)\n",
    "\n",
    "    print(\"...finished dispatch splitting...\")\n",
    "    print(\"/// dispatch transformation ended ///\")\n",
    "\n",
    "    return loads_df, hours_df, smu_df, errors, smu_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4081cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dpr\n",
    "def transform_dpr(df):\n",
    "    \n",
    "    print(\"/// dpr_df transformation started ///\")\n",
    "    \n",
    "    master_dpr = df[2].copy()\n",
    "\n",
    "    # Drop data > 2021\n",
    "    master_dpr = master_dpr[master_dpr['date'].dt.year > 2021]\n",
    "\n",
    "    # Select loads only\n",
    "    master_dpr = master_dpr[master_dpr['entry_type'].str.lower() == 'load']\n",
    "\n",
    "    # Create month_year col and groupby\n",
    "    master_dpr['month_year'] = master_dpr['date'].dt.month_name().str[:3] + '-' + master_dpr['date'].dt.year.astype('string').str[2:]\n",
    "    master_dpr.sort_values(by=['date'] , inplace=True)\n",
    "    master_dpr = master_dpr.groupby([\"month_year\"],as_index=False, sort=False).agg(\n",
    "        {\n",
    "            'amount' : 'sum',\n",
    "            '#loads' : 'sum',\n",
    "            'truck_factor' : 'mean'\n",
    "        }\n",
    "    ).round(decimals=2)\t\n",
    "\n",
    "    master_dpr.columns = ['month_year', 'amount', 'loads_count', 'truck_factor']\n",
    "    master_dpr.drop(columns='amount', inplace=True)\n",
    "    \n",
    "    print(\"/// dpr_df transformation ended ///\")\n",
    "\n",
    "    return master_dpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "596279e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Performance\n",
    "def transform_performance(df):\n",
    "\n",
    "    print(\"/// performance_df transformation started ///\")\n",
    "\n",
    "    performance_df = df[1].copy()\n",
    "\n",
    "    # drop all Na\n",
    "    performance_df.dropna(how='all', inplace=True)\n",
    "    performance_df.replace(['0:00:00','00:00:00','0'], np.nan, inplace=True)\n",
    "    performance_df = performance_df[performance_df['distance'] > 0]\n",
    "\n",
    "    performance_df.rename(columns={'exc' : 'equipment_id'}, inplace=True)\n",
    "    performance_df['shift'] = performance_df['shift'].str.capitalize()\n",
    "    performance_df.sort_values(by=['date','shift','equipment_id'], inplace=True)\n",
    "    performance_df['id_shift'] = performance_df['date'].dt.strftime('%d%m%y') + performance_df['shift'].str[:1] + performance_df['equipment_id'] \n",
    "    performance_df['shift'] = performance_df['shift'].str.capitalize()\n",
    "    performance_df = performance_df.reindex(columns = ['id_shift', 'date', 'shift', 'equipment_id', 'distance'])\n",
    "    print(\"/// performance_df transformation finished ///\")\n",
    "\n",
    "    return performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f957bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Meters\n",
    "def transform_meters(df):\n",
    "    \n",
    "    print(\"/// meters_df transformation started ///\")\n",
    "    \n",
    "    meters_df = df[3].copy()\n",
    "    \n",
    "    meters_df.columns = meters_df.columns.str.replace('/','_')\n",
    "    meters_df.drop(columns= ['id', 'comments', 'sample_tube', 'inside_wmc_boundary'], inplace=True)\n",
    "    meters_df.rename(columns= {'rig' : 'equipment_id', 'hole#' : 'hole_id'}, inplace=True)\n",
    "    meters_df['drilled_depth'] = pd.to_numeric(meters_df['drilled_depth'], errors='coerce')\n",
    "    meters_df = meters_df[meters_df['drilled_depth'] >= 0]\n",
    "    meters_df['date'] = pd.to_datetime(meters_df['date'], errors='coerce')\n",
    "    meters_df = meters_df[meters_df['date'].isna() == False]\n",
    "    meters_df.sort_values(by=['date','shift','equipment_id'], inplace=True)\n",
    "    meters_df['id_shift'] = meters_df['date'].dt.strftime('%d%m%y') + meters_df['shift'].str[:1] + meters_df['equipment_id']\n",
    "    meters_df['hammer_s_n'].replace(['BIT S/N', 'Hammer S/N'] , 'N/A', inplace=True)\n",
    "    meters_df = meters_df.reindex(columns= ['id_shift', 'date', 'shift', 'crew', 'drilling_type', 'equipment_id', 'driller',\n",
    "           'location', 'hole_id', 'hole_type', 'drilled_depth', 'bit_s_n',\n",
    "           'hammer_s_n', 'pen_rate', 'section'])\n",
    "    \n",
    "    print(\"/// meters_df transformation ended ///\")\n",
    "    \n",
    "    return meters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92c6b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Rigs Hours\n",
    "def transform_rigs_hours(df):\n",
    "    \n",
    "    def activity_category(x):\n",
    "    \n",
    "        y = 'N/A'\n",
    "\n",
    "        if x == 'dt':\n",
    "            y = 'Downtime'\n",
    "        elif x == 'maint':\n",
    "            y = 'Maintenance'\n",
    "        elif x == 'wt':\n",
    "            y = 'Worktime'\n",
    "        elif x == 'sb' or x == 'standby':\n",
    "            y = 'Standby'\n",
    "        elif x == 'Drilling':\n",
    "            y = 'Drilling'\n",
    "\n",
    "        return y \n",
    "    \n",
    "    print(\"/// rigs_hours_df transformation started ///\")\n",
    "    \n",
    "    rigs_hours = df[4].copy()\n",
    "    \n",
    "    rigs_hours.columns = ['date', 'shift', 'rig#', 'drilling_type', 'Drilling_Drilling hrs',\n",
    "       'wt_Directional drilling', 'wt_Survey', 'wt_Core orientation',\n",
    "       'dt_Tramming', 'wt_Setup - Pulldown',\n",
    "       'wt_Re-drill', 'wt_Condition hole',\n",
    "       'wt_ream_open_out_hole', 'wt_reaming_casing',\n",
    "       'wt_Freeing stuck rods - Ground conditions',\n",
    "       'wt_Freeing stuck Casing - Ground conditions',\n",
    "       'wt_Freeing stuck rods - Operating fault',\n",
    "       'wt_RDT change',\n",
    "       'wt_Change - Reduce drill mode',\n",
    "       'wt_tripping_end_of_hole', 'wt_tripping_stuck_tube',\n",
    "       'wt_tripping_dropped_core', 'wt_tripping_lower/retrieve_casing',\n",
    "       'wt_Retrieving dropped RDT',\n",
    "       'wt_tripping_broken_wireline', 'wt_cement_hole',\n",
    "       'wt_RC Inner tube', 'wt_RC Sample tube',\n",
    "       'wt_Checking - Changing rods', 'wt_other_work_time',\n",
    "       'reason\\n(text)', 'standby_Client Delay power',\n",
    "       'standby_Client Water', 'standby_Client Fuel',\n",
    "       'standby_Client vent - air', 'sb_Client - Blast',\n",
    "       'standby_Client Access',\n",
    "       'standby_Client Waiting for areas - drill pad',\n",
    "       'standby_client Waiting for mark-up',\n",
    "       'standby_client Waiting for client rep',\n",
    "       'standby_client cement drying', 'standby_CAPITAL Mining',\n",
    "       'standby_client Non chargeable', 'reason\\n(text).1',\n",
    "       'maint_Daily service', 'maint_Planned', 'maint_Break down',\n",
    "       'reason\\n(text).2', 'maint_Operator damage', 'reason\\n(text).3',\n",
    "       'dt_Safety meeting - Toolbox', 'dt_Pre-start - Handover',\n",
    "       'dt_Housekeeping', 'dt_Waiting for CD safety',\n",
    "       'dt_Waiting for CD water/fuel', 'dt_Waiting for equipment',\n",
    "       'dt_Waiting for people', 'dt_Refuel', 'dt_Refilling water',\n",
    "       'dt_Retrieving lost RDT', 'dt_monthly_rig_inspection',\n",
    "       'dt_Travel to rig', 'dt_Weather', 'dt_Religious time',\n",
    "       'dt_Lunch', 'dt_Other', 'reason\\n(text).4']\n",
    "    \n",
    "    rigs_hours.rename(columns= {'rig#' : 'equipment_id'}, inplace=True)\n",
    "    rigs_hours['date'] = pd.to_datetime(rigs_hours['date'], errors='coerce')\n",
    "    rigs_hours = rigs_hours[rigs_hours['date'].isna() == False]\n",
    "    rigs_hours.sort_values(by=['date','shift','equipment_id'], inplace=True)\n",
    "    rigs_hours['id_shift'] = rigs_hours['date'].dt.strftime('%d%m%y') + rigs_hours['shift'].str[:1] + rigs_hours['equipment_id']  \n",
    "    rigs_hours = rigs_hours[rigs_hours['drilling_type'] != '-']\n",
    "    rigs_hours.dropna(axis=1, how='all', inplace=True)\n",
    "    rigs_hours_melted = pd.melt(rigs_hours, id_vars= ['id_shift', 'date', 'shift', 'equipment_id', 'drilling_type'], var_name='activity_type', value_name= 'hours' )\n",
    "    rigs_hours_melted = rigs_hours_melted.sort_values(by=['date', 'shift', 'equipment_id', 'activity_type'], ignore_index=True)\n",
    "    rigs_hours_melted['hours'] = pd.to_numeric(rigs_hours_melted['hours'], errors='coerce')\n",
    "    rigs_hours_melted = rigs_hours_melted[rigs_hours_melted['hours'] > 0]\n",
    "    rigs_hours_melted['activity_category'] = rigs_hours_melted['activity_type'].str.split('_').str[0].map(activity_category)\n",
    "    rigs_hours_melted['activity_type'] = rigs_hours_melted['activity_type'].str.split('_').str[1]\n",
    "    print(\"/// rigs_hours_df transformation ended ///\")\n",
    "    \n",
    "    return rigs_hours_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a0db3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    " def transform_data(df):\n",
    "        \n",
    "    print('\\n*** START DATA TRANSFORMATION ***\\n')\n",
    "        \n",
    "    new_dfs = general_clean(df)\n",
    "    performance_df = transform_performance(new_dfs)\n",
    "    dpr_df = transform_dpr(new_dfs)\n",
    "    loads_df, hours_df, smu_df, errors, smu_duplicates = transform_dispatch(new_dfs, dpr_df)\n",
    "    meters_df = transform_meters(new_dfs)\n",
    "    rigs_hours_df = transform_rigs_hours(new_dfs)\n",
    "    \n",
    "    print('\\n*** DATA TRANSFORMATION ENDED ***\\n')\n",
    "\n",
    "    return performance_df, dpr_df, loads_df, hours_df, smu_df, errors, meters_df, rigs_hours_df, smu_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4cff1fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** START DATA EXTRACTION ***\n",
      "\n",
      "Reading Dispatch Files...\n",
      "\n",
      "dispatch files number =1\n",
      "\n",
      "Reading dispatch\\01. Database Master (february_2023 ).xlsx\n",
      "Columns = 22\n",
      "Master df Columns = 22\n",
      "finished dispatch\\01. Database Master (february_2023 ).xlsx\n",
      "\n",
      "last dispatch date = 9682   2023-02-03\n",
      "Name: DATE, dtype: datetime64[ns]\n",
      "\n",
      "Dispatch Files Reading Ended Successfully...\n",
      "\n",
      "Reading Performance Files...\n",
      "\n",
      "performance files number = 1\n",
      "finished performance\\DPR Daily Production Report February Performance.xlsx\n",
      "Columns = 4\n",
      "last performance date = 249   NaT\n",
      "Name: DATE, dtype: datetime64[ns]\n",
      "\n",
      "Performance Files Reading Ended Successfully...\n",
      "\n",
      "Reading dpr Files...\n",
      "\n",
      "dpr files number = 1\n",
      "finished dpr\\DPR-Daily Production Report_February.xlsx\n",
      "Columns = 5\n",
      "last performance date = 20015   2023-02-03\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "Performance Files Reading Ended Successfully...\n",
      "\n",
      "Reading drilling Files...\n",
      "\n",
      "daily data files number = 1\n",
      "last meters date = 55973   NaT\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "last rigs_hours date = 2037   NaT\n",
      "Name: Date, dtype: datetime64[ns]\n",
      "\n",
      "Drilling Files Reading Ended Successfully...\n",
      "\n",
      "Reading Reason codes...\n",
      "\n",
      "\n",
      "Reason codes Reading Ended Successfully...\n",
      "\n",
      "***DATA EXTRACTION ENDED ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = list(extract_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ab81fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** START DATA TRANSFORMATION ***\n",
      "\n",
      "/// performance_df transformation started ///\n",
      "/// performance_df transformation finished ///\n",
      "/// dpr_df transformation started ///\n",
      "/// dpr_df transformation ended ///\n",
      "/// dispatch transformation started ///\n",
      "Converting production values to numeric...\n",
      "Found and dropped 0 errors\n",
      "...Started dispatch splitting...\n",
      "...finished dispatch splitting...\n",
      "/// dispatch transformation ended ///\n",
      "/// meters_df transformation started ///\n",
      "/// meters_df transformation ended ///\n",
      "/// rigs_hours_df transformation started ///\n",
      "/// rigs_hours_df transformation ended ///\n",
      "\n",
      "*** DATA TRANSFORMATION ENDED ***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distance_df, truck_factor_df, loads_df, hours_df, smu_df, errors, meters_df, rigs_hours_df, smu_duplicates = transform_data(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2669f6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Equipments df\n",
    "def extract_equipment_Drilling_types(df1 = dfs[0], df2 = meters_df):\n",
    "    '''\n",
    "    Exctract equipment models and store them in a seperate dataframe.\n",
    "    by default df1 = dispatch raw df, df2 = meters_df\n",
    "    '''\n",
    "    def rigs_types(rig):\n",
    "    \n",
    "        rig_type = None\n",
    "    \n",
    "        if rig[3:] == '081' or rig[3:] == '067':\n",
    "            rig_type = 'DM30'\n",
    "\n",
    "        elif rig[3:] == '100' or rig[3:] == '101' or rig[3:] == '102' or rig[3:] == '115' or rig[3:] == '129':\n",
    "            rig_type = 'DM45'\n",
    "\n",
    "        elif rig[3:] == '111' or rig[3:] == '112' or rig[3:] == '122' or rig[3:] == '121' or rig[3:] == '130' or rig[3:] == '170' :\n",
    "            rig_type = 'D65'\n",
    "\n",
    "        elif rig[3:] == '116' or rig[3:] == '126' or rig[3:] == '131':\n",
    "            rig_type = 'DML'\n",
    "\n",
    "        elif rig[3:] == '140' or rig[3:] == '141' or rig[3:] == '142':\n",
    "            rig_type = 'D65mkII'\n",
    "\n",
    "        elif rig[3:] == '151' or rig[3:] == '152' or rig[3:] == '153' or rig[3:] == '154':\n",
    "            rig_type = 'DR410i'\n",
    "\n",
    "        elif rig[3:] == '125':\n",
    "            rig_type = 'Terex'\n",
    "\n",
    "        elif rig[3:] == '092' or rig[3:] == '157' or rig[3:] == '173':\n",
    "            rig_type = 'Explorac'\n",
    "\n",
    "        elif rig[3:] == '028':\n",
    "            rig_type = 'Unicon'\n",
    "\n",
    "        return rig_type\n",
    "\n",
    "\n",
    "    equipment_df = pd.DataFrame(columns=['Equipment_id', 'Equipment_oem_model', 'Equipment_type', 'Equipment_department'])\n",
    "    \n",
    "    # first df for Mining\n",
    "    equipment0 = df1[['EQUIPMENT ID', 'EQUIPMENT OEM MODEL']].drop_duplicates().reset_index(drop=True)\n",
    "    equipment0 = equipment0[equipment0['EQUIPMENT ID'].isna() == False]\n",
    "    equipment0['Equipment_type'] = equipment0['EQUIPMENT ID'].map(lambda x : 'Excavator'\n",
    "    if x[:3] == 'EXC' else 'Truck' if x[:3] == 'HMT' else 'Grader' if x[:3] =='GRA' else 'Water_Truck' if x[:3] == 'HWT'\n",
    "    else 'Dozer' if x[:2] == 'DZ' else 'Wheel_Dozer' if x[:3] == 'RDT' else 'N/A' )\n",
    "    equipment0['equipment_department'] = 'Mining'\n",
    "    equipment0.columns = ['Equipment_id', 'Equipment_oem_model', 'Equipment_type', 'Equipment_department']\n",
    "    \n",
    "    # second one for Drilling\n",
    "    equipment1 = pd.DataFrame(columns=['Equipment_id', 'Equipment_oem_model', 'Equipment_type', 'Equipment_department'])\n",
    "    equipment1['Equipment_id'] = meters_df['Equipment_id'].drop_duplicates()\n",
    "    equipment1['Equipment_oem_model'] = equipment1['Equipment_id'].map(rigs_types)\n",
    "    equipment1['Equipment_type'] = 'Rig'\n",
    "    equipment1['Equipment_department'] = 'Drilling'\n",
    "    \n",
    "    equipment_df = pd.concat([equipment0, equipment1], ignore_index=True)\n",
    "    \n",
    "    # Get Drilling types df\n",
    "    drilling_types_df = meters_df['Drilling_type'].drop_duplicates()\n",
    "    \n",
    "    return equipment_df, drilling_types_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f5c7301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reason_codes_df = dfs[5]\n",
    "final_dfs = [distance_df, truck_factor_df, loads_df, hours_df, smu_df, errors, meters_df, rigs_hours_df, reason_codes_df]\n",
    "for i in range(len(final_dfs)):\n",
    "    final_dfs[i].columns = final_dfs[i].columns.str.capitalize()\n",
    "    final_dfs[i].columns = final_dfs[i].columns.str.replace('Date', 'Date_value')\n",
    "\n",
    "equipment_df, drilling_types_df = extract_equipment_Drilling_types()\n",
    "date_path = 'date_dimension/date_dimension.xlsx'\n",
    "date_df = pd.read_excel(date_path)\n",
    "shifts_df = smu_df['Shift'].drop_duplicates()\n",
    "\n",
    "\n",
    "nonup_dfs = [equipment_df, drilling_types_df]\n",
    "updatable_dfs = [distance_df, truck_factor_df, loads_df, hours_df, smu_df, meters_df, rigs_hours_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c5c41",
   "metadata": {},
   "source": [
    "### 3 - Connect to MSSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3989ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mssql_connect():\n",
    "    conn = None\n",
    "    print(\"ESTABLISHING A CONNECTION TO MSSQL DB...\")\n",
    "    try:\n",
    "\n",
    "        connection_url = sa.engine.URL.create(\n",
    "                                \"mssql+pyodbc\",\n",
    "                                username=\"cl-mining-drilling-reports\",\n",
    "                                password=\"px97#@k4g#JGgApc\",\n",
    "                                host=\"capital-limited-sqlserver01.database.windows.net\",\n",
    "                                port=1433,\n",
    "                                database=\"cl-mining-drilling-reports\",\n",
    "                                query={\n",
    "                                    \"driver\": \"ODBC Driver 18 for SQL Server\",\n",
    "                                    \"TrustServerCertificate\": \"yes\",\n",
    "                                    \"MARS_Connection\": \"yes\"},\n",
    "                            )\n",
    "        sqlalch_db = sa.create_engine(connection_url, fast_executemany=True)\n",
    "        insp = sa.inspect(sqlalch_db)\n",
    "        conn = sqlalch_db.connect()\n",
    "        print(\"Connected!\")\n",
    "\n",
    "        # create Loads table\n",
    "        def create_tables(): \n",
    "                print(\"Creating Tables...\")\n",
    "                loads_table = sa.text(\n",
    "                    \"CREATE TABLE Loads ( \"\n",
    "                    \"Id_shift varchar(20) NOT NULL,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Time time(0),\"\n",
    "                    \"Operator_name varchar(max),\"\n",
    "                    \"Crew varchar(1),\"\n",
    "                    \"Equipment_id varchar(8) NOT NULL,\"\n",
    "                    \"Related_equipment varchar(8),\"\n",
    "                    \"Location_pit varchar(max),\"\n",
    "                    \"Material_code varchar(8),\"\n",
    "                    \"Loads int,\"\n",
    "                    \"Destination varchar(max),\"\n",
    "                    \"Reason_code int,\"\n",
    "                    \"Dispatcher_name varchar(max),\"\n",
    "                    \"Bcm float(2))\"\n",
    "                )\n",
    "                hours_table = sa.text(\n",
    "                    \"CREATE TABLE Mining_hours ( \"\n",
    "                    \"Id_shift varchar(20) NOT NULL,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Time time(0),\"\n",
    "                    \"Operator_name varchar(max),\"\n",
    "                    \"Crew varchar(1),\"\n",
    "                    \"Reason_activity varchar(max),\"\n",
    "                    \"Engine_state_code varchar(3),\"\n",
    "                    \"Equipment_id varchar(8),\"\n",
    "                    \"Location_pit varchar(max),\"\n",
    "                    \"Hours float(6),\"\n",
    "                    \"Activity_code int,\"\n",
    "                    \"Reason_code int NOT NULL,\"\n",
    "                    \"Dispatcher_name varchar(max))\"\n",
    "                ) \n",
    "                smu_table = sa.text(\n",
    "                    \"CREATE TABLE Mining_SMU ( \"\n",
    "                    \"Id_shift varchar(20) PRIMARY KEY,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Equipment_id varchar(8),\"\n",
    "                    \"Dispatcher_name varchar(max),\"\n",
    "                    \"Smu_start float(1),\"\n",
    "                    \"Smu_end float(1),\"\n",
    "                    \"Smu float(1))\"\n",
    "                ) \n",
    "                distance_table = sa.text(\n",
    "                    \"CREATE TABLE Distance ( \"\n",
    "                    \"Id_shift varchar(20) PRIMARY KEY,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Equipment_id varchar(8),\"\n",
    "                    \"Distance float(2))\"\n",
    "                ) \n",
    "                meters_table = sa.text(\n",
    "                    \"CREATE TABLE Meters ( \"\n",
    "                    \"Id_shift varchar(20) NOT NULL,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Crew varchar(1),\"\n",
    "                    \"Drilling_type varchar(max),\"\n",
    "                    \"Equipment_id varchar(8) NOT NULL,\"\n",
    "                    \"Driller varchar(max),\"\n",
    "                    \"Location varchar(max),\"\n",
    "                    \"Hole_id varchar(10) NOT NULL,\"\n",
    "                    \"Hole_type varchar(20),\"\n",
    "                    \"Drilled_depth float(1) NOT NULL,\"\n",
    "                    \"Bit_s_n varchar(12) NOT NULL,\"\n",
    "                    \"Hammer_s_n varchar(8) NOT NULL,\"\n",
    "                    \"Pen_rate float(2),\"\n",
    "                    \"Section varchar(10) NOT NULL)\"\n",
    "                )  \n",
    "                rigs_hours_table = sa.text(\n",
    "                    \"CREATE TABLE Rigs_hours ( \"\n",
    "                    \"Id_shift varchar(20) NOT NULL,\"\n",
    "                    \"Date_value date NOT NULL,\"\n",
    "                    \"Shift varchar(5) NOT NULL,\"\n",
    "                    \"Equipment_id varchar(8) NOT NULL,\"\n",
    "                    \"Drilling_type varchar(max) NOT NULL,\"\n",
    "                    \"Activity_type varchar(max) NOT NULL,\"\n",
    "                    \"Hours float(2) NOT NULL,\"\n",
    "                    \"Activity_category varchar(max) NOT NULL)\"                \n",
    "                ) \n",
    "                truck_factor_table = sa.text(\n",
    "                    \"CREATE TABLE Truck_factor ( \"\n",
    "                    \"Month_year varchar(6) PRIMARY KEY,\"\n",
    "                    \"Loads_count int NOT NULL,\"\n",
    "                    \"Truck_factor float(2) NOT NULL)\"\n",
    "                ) \n",
    "                equipment_table = sa.text(\n",
    "                    \"CREATE TABLE Equipment ( \"\n",
    "                    \"Equipment_id varchar(8) PRIMARY KEY,\"\n",
    "                    \"Equipment_oem_model varchar(12),\"\n",
    "                    \"Equipment_type varchar(12),\"\n",
    "                    \"Equipment_department varchar(12))\"\n",
    "                )\n",
    "                reason_codes_table = sa.text(\n",
    "                    \"CREATE TABLE Reason_codes ( \"\n",
    "                    \"Category varchar(15) NOT NULL,\"\n",
    "                    \"Reason_code int,\"\n",
    "                    \"Reason_code_type varchar(12))\"\n",
    "                )\n",
    "                date_table = sa.text(\n",
    "                    \"CREATE TABLE Date_dim ( \"\n",
    "                    \"Date_value date PRIMARY KEY,\"\n",
    "                    \"Month_name varchar(3) NOT NULL,\"\n",
    "                    \"Day_name varchar(3) NOT NULL,\"\n",
    "                    \"Week_of_year int NOT NULL,\"\n",
    "                    \"Quarter int NOT NULL,\"\n",
    "                    \"First_day_of_month date NOT NULL,\"\n",
    "                    \"Last_day_of_month date NOT NULL)\"\n",
    "                )\n",
    "                drilling_types_table = sa.text(\n",
    "                    \"CREATE TABLE Drilling_types( \"\n",
    "                    \"Drilling_type varchar(max) PRIMARY KEY) \"\n",
    "                )\n",
    "                shifts_table = sa.text(\n",
    "                    \"CREATE TABLE Shifts( \"\n",
    "                    \"Shift varchar(5) PRIMARY KEY) \"\n",
    "                )\n",
    "\n",
    "\n",
    "                my_tables = [loads_table, hours_table, smu_table, distance_table, \n",
    "                             meters_table, rigs_hours_table, truck_factor_table, equipment_table, \n",
    "                             drilling_types_table]\n",
    "\n",
    "                print(\"\\n*** CREATING TABLES ***\\n\")\n",
    "                for table in my_tables:\n",
    "                    conn.execute(table)\n",
    "                    \n",
    "                    '''\n",
    "                    print(\"*** Checking if table exist ***\")\n",
    "                    if insp.has_table(table, schema=\"dbo\") == False:\n",
    "                        print(\"Table {} doesn't exist\".format(table.name))\n",
    "                        conn.execute(table)\n",
    "                        print(\"Created table.\")\n",
    "                    \n",
    "                    else : print(\"Table already exists.\")'''\n",
    "\n",
    "        def add_data():\n",
    "\n",
    "            print(\"\\n***Adding data to db***\\n\")\n",
    "\n",
    "            # Define updatable tables dictionary        \n",
    "            updatable_db_tables_names = ['Distance', 'Truck_factor',\n",
    "                                         'Loads', 'Mining_hours', 'Mining_SMU', 'Meters','Rigs_hours']\n",
    "            print(\"Building tables reps...\\n\")\n",
    "            updatable_table_reps = [sa.Table(table, sa.MetaData(), autoload_with = conn) for table in updatable_db_tables_names]\n",
    "            updatable_tables_dfs_dict = dict(zip(updatable_table_reps, updatable_dfs))\n",
    "\n",
    "\n",
    "            for table, df in updatable_tables_dfs_dict.items():\n",
    "\n",
    "                # delete the current month data from the db table\n",
    "                # truck factor table\n",
    "                print(\"*** Table: {} *** \".format(table.name))\n",
    "                if 'Month_year' in df.columns:\n",
    "                    month_year = df['Month_year'].to_list()\n",
    "                    for i in month_year:\n",
    "                        conn.execute(sa.delete(table=table).where(table.c.Month_year >= i)) \n",
    "                    print('Deleted {}'.format(month_year))\n",
    "\n",
    "                    print(\"...Adding Data...\")\n",
    "                    df.to_sql(name= table.name, con=conn, schema='dbo', if_exists='append', index=False)\n",
    "                    print(\"Added {}\\n\".format(table.name))\n",
    "\n",
    "                # Other tables\n",
    "                elif 'Date_value' in df.columns:\n",
    "                    min_date = df['Date_value'].dt.date.min()\n",
    "                    conn.execute(sa.delete(table=table).where(table.c.Date_value >= min_date))\n",
    "                    print('Deleted Dates from: {} From Table: {}'.format(min_date, table.name))\n",
    "\n",
    "                    print(\"...Adding Data...\")\n",
    "                    df.to_sql(name= table.name, con=conn, schema='dbo', if_exists='append', index=False)\n",
    "                    print(\"Added\\n\")\n",
    "\n",
    "\n",
    "             # Define non-updatable tables dictionary        \n",
    "            nonup_db_tables_names = ['Equipment', 'Drilling_types']\n",
    "            nonup_table_reps = [sa.Table(table, sa.MetaData(), autoload_with = conn) for table in nonup_db_tables_names]\n",
    "\n",
    "            nonup_tables_dfs_dict = dict(zip(nonup_table_reps, nonup_dfs))\n",
    "\n",
    "            for table, df in nonup_tables_dfs_dict.items():\n",
    "                print(\"***Table: {}***\".format(table.name))\n",
    "                db_table = pd.DataFrame(conn.execute(sa.select(sa.text('*')).select_from(table)).fetchall())\n",
    "                new_rows_df = db_table.merge(df, how='outer', indicator=True).query('_merge == \"right_only\"').drop(columns='_merge')\n",
    "\n",
    "\n",
    "                if rows_count ==0 :\n",
    "                    conn.execute(sa.delete(table=table))\n",
    "                    print('Deleted table {}'.format(table.name))\n",
    "                    print(\"...Adding Data...\")\n",
    "                    df.to_sql(name= table.name, con=conn, schema='dbo', if_exists='append', index=False)\n",
    "                    print(\"Added {}\\n\".format(table.name))\n",
    "\n",
    "\n",
    "                else:\n",
    "                    print(\"No new Data to add\")\n",
    "\n",
    "\n",
    "        #create_tables() \n",
    "        add_data()               \n",
    "\n",
    "\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            print('Closing db connection...')\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "446db561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTABLISHING A CONNECTION TO MSSQL DB...\n",
      "Connected!\n",
      "\n",
      "***Adding data to db***\n",
      "\n",
      "Building tables reps...\n",
      "\n",
      "*** Table: Distance *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Distance\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "*** Table: Truck_factor *** \n",
      "Deleted ['Dec-22', 'Jan-23', 'Feb-23']\n",
      "...Adding Data...\n",
      "Added Truck_factor\n",
      "\n",
      "*** Table: Loads *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Loads\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "*** Table: Mining_hours *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Mining_hours\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "*** Table: Mining_SMU *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Mining_SMU\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "*** Table: Meters *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Meters\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "*** Table: Rigs_hours *** \n",
      "Deleted Dates from: 2023-02-01 From Table: Rigs_hours\n",
      "...Adding Data...\n",
      "Added\n",
      "\n",
      "***Table: Equipment***\n",
      "No new Data to add\n",
      "***Table: Drilling_types***\n",
      "No new Data to add\n",
      "Closing db connection...\n"
     ]
    }
   ],
   "source": [
    "mssql_connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40013504",
   "metadata": {},
   "outputs": [],
   "source": [
    "driling_target_path = 'drilling_targets/target.xlsx'\n",
    "Drilling_targets_df = pd.read_excel(driling_target_path, sheet_name='Sheet2', usecols='P:AD')\n",
    "Drilling_targets_df = Drilling_targets_df.round(1)\n",
    "Drilling_targets_df.replace(0,np.nan, inplace=True)\n",
    "Drilling_targets_df.dropna(how='all', inplace=True)\n",
    "Hole_types_df = meters_df[['drilling_type', 'hole_type']].drop_duplicates()\n",
    "Hole_types_df = Hole_types_df[Hole_types_df['hole_type'] !=0]\n",
    "Hole_types_df['is_Redrill'] = Hole_types_df['hole_type'].map(lambda x:True if 'Re-Drill' in x else False)\n",
    "Hole_types_df.columns = Hole_types_df.columns.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hole_types_table = sa.text(\n",
    "    \"CREATE TABLE Hole_types ( \"\n",
    "    \"Drilling_type varchar(40) NOT NULL ,\"\n",
    "    \"Hole_type varchar(20) PRIMARY KEY ,\"\n",
    "    \"Is_redrill bit NOT NULL)\"\n",
    ")\n",
    "\n",
    "Drilling_targets_table = sa.text(\n",
    "    \"CREATE TABLE Hole_types ( \"\n",
    "    \"Month_year varchar(5) PRIMARY KEY ,\"\n",
    "    \"Total_BH_forecast float(1) ,\"\n",
    "    \"Total_BH_budget float(1),\"\n",
    "    \"SGM_forecast float(1),\"\n",
    "    \"SGM_budget float(1),\"\n",
    "    \"WMC_forecast float(1),\"\n",
    "    \"WMC_budget float(1),\"\n",
    "    \"Total_BH_daily float(1),\"\n",
    "    \"Total_BH_budget_daily float(1),\"\n",
    "    \"SGM_forecast_daily float(1),\"\n",
    "    \"SGM_budget_daily float(1),\"\n",
    "    \"WMC_forecast_daily float(1),\"\n",
    "    \"WMC_budget_daily float(1),\"\n",
    "    \"Total_GC float(1),\"\n",
    "    \"Total_GC_daily float(1))\"\n",
    ")\n",
    "drilling_types_table = sa.text(\n",
    "                    \"CREATE TABLE Drilling_types( \"\n",
    "                    \"Drilling_type varchar(40) PRIMARY KEY) \"\n",
    "                )\n",
    "#conn.execute(Hole_types_table)\n",
    "#conn.execute(drilling_types_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca527e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mining_monthly_targets_path = 'mining_targets/monthly_budget_forecast.csv'\n",
    "#mining_monthly_targets_df = pd.read_csv(mining_monthly_targets_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
